---
title: "Hpgltools examples using a small bacterial data set."
author: "atb abelew@gmail.com"
date: "`r Sys.Date()`"
output:
 html_document:
  theme: cosmo
  highlight: tango
  fig_height: 7
  fig_width: 7
  fig_caption: true
  code_folding: show
  self_contained: true
  keep_md: true
  toc: true
  toc_float:
    collapsed: false
    smooth_scroll: false
vignette: >
  %\VignetteIndexEntry{hpgltools_examples}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---

```{r options, include=FALSE}
## These are the options I tend to favor
library("hpgltools")
knitr::opts_knit$set(
    progress = TRUE,
    verbose = TRUE,
    width = 90,
    echo = TRUE)
knitr::opts_chunk$set(
    error = TRUE,
    fig.width = 8,
    fig.height = 8,
    dpi = 96)
options(
    digits = 4,
    stringsAsFactors = FALSE,
    knitr.duplicate.label = "allow")
ggplot2::theme_set(ggplot2::theme_bw(base_size=10))
set.seed(1)
rmd_file <- "01_hpgltools_bacterial_examples.Rmd"
```

```{r rendering, include=FALSE, eval=FALSE}
## This block is used to render a document from within it.
rmarkdown::render(rmd_file)

## An extra renderer for pdf output
rmarkdown::render(rmd_file, output_format="pdf_document", output_options=c("skip_html"))

## Or to save/load large Rdata files.
hpgltools:::saveme()
hpgltools:::loadme()
rm(list=ls())
```

# Introduction

hpgltools was written to make working with high-throughput data
analyses easier. These analyses generally fall into a few stages:

1.  Data visualization and outlier/batch evaluation
2.  Differential expression analyses
 a. Visualization and export of these results
3.  Gene ontology/KEGG analyses
 a. Visualization and export of these results
4.  Circos visualization

Before any of these tasks may be performed, the data must be loaded
into memory.  hpgltools attempts to make this easier with
create_expt() and subset_expt().

# Loading (meta)data and annotations

The following examples will use a real data set from a recent
experiment in our lab.  The raw data was processed using a mix of
trimmomatic, biopieces, bowtie, samtools, and htseq.  The final count
tables were deposited into the 'preprocessing/count_tables/' tree.
The resulting data structure was named 'most_v0M1,' named because it
is comprised of count tables with 0 mismatches and 1 randomly-placed
multi-match.

The annotation file was mgas_5005.gff.xz residing in
'reference/gff/'.

The count tables and meta-data were loaded through the create_expt()
function and the genome annotations were loaded with gff2df().

```{r loading_data}
library(hpgltools)
data_file <- system.file("cdm_expt.rda", package="hpgltools")
cdm <- new.env()
load(data_file, envir=cdm)
rm(data_file)

ls()
## 2 variables should exist now: rmd_file in case I want to knitr this file, cdm which is a list including the data required to make an expressionset.

expt <- create_expt(count_dataframe=cdm$cdm_counts, metadata=cdm$cdm_metadata, gene_info=cdm$gene_info)
## The gff information is in 'annotations'
## The experiment is in most_v0M1
## Here is the meta-data! (well, the first 6 lines anyway).
knitr::kable(head(expt$design))
summary(expt)
```

The data structure generated by create_expt() is a list containing the
following slots:

* initial_metadata:        A backup of the metadata
* original_expressionset:  A backup of the raw counts
* expressionset:           The current count data
* samples:                 A data frame of metadata used for subsets
* design:                  The design of the experiment
* definitions:             Extended design information, these are
  probably redundant and should be pruned.
* stages:                  The experimental stage
* types:                   Cell types
* conditions:              Experimental condition
* batches:                 Experimental batch
* samplenames:             Names of the samples
* colors:                  Colors chosen for graphs and such
* names:                   Bringing together the condition/batch
* filtered:                low-count filtering status of the counts
* transform:               transformation applied to the counts
* norm:                    normalization applied to the counts
* convert:                 cpm/rpkm/etc applied to the data
* original_libsize:        the library sizes before normalization
* columns:                 A backup of the sample names

# Raw metrics

One possibility would be to examine the data in its unmolested state:

```{r graph_original}
raw_metrics <- sm(graph_metrics(expt, qq=TRUE))
## View a raw library size plot
raw_metrics$libsize
## Or boxplot to see the data distribution
raw_metrics$boxplot
## The warning is because it automatically uses a log scale and there are some 0 count genes.
## Perhaps you prefer density plots
raw_metrics$density
## quantile/quantile plots compared to the median of all samples
raw_metrics$qqrat
## Here we can see some samples are differently 'shaped' compared to the median than others
## There are other plots one may view, but this data set is a bit too crowded as is.
## The following summary shows the other available plots:
summary(raw_metrics)
```

# Subsetting data

On the other hand, we might take a subset of the data to
focus on the late-log vs. early-log samples.

The expt_subset() function allows one to pull material from the
experimental design.

Once we have a smaller data set, we can more easily use PCA to see how
the sample separate.

```{r subset_data}
head(expt$design)
## elt stands for: "early/late in thy"
batch_a <- expt_subset(expt, subset="batch=='a'")
batch_b <- expt_subset(expt, subset="batch=='b'")

a_metrics <- graph_metrics(batch_a)
a_metrics$pcaplot
b_metrics <- graph_metrics(batch_b)
b_metrics$pcaplot
```

# Normalizing data

It is pretty obvious that the raw data is a bit jumbled according to
PCA.  This is not paricularly suprising since we didn't normalize it
at all.

```{r normalize_subset}
## doing nothing to the data except log2 transforming it has a surprisingly large effect
norm_test <- normalize_expt(expt, transform="log2")
plot_pca(norm_test)$plot
## Looks like 2 samples got switched
## a quantile normalization alone affect some, but not all of the data
norm_test <- sm(normalize_expt(expt, norm="quant"))
plot_pca(norm_test)$plot
## cpm alone brings out some samples, too
norm_test <- sm(normalize_expt(expt, convert="cpm"))
plot_pca(norm_test)$plot
## low count filtering has some effect, too
norm_test <- sm(normalize_expt(expt, filter="pofa"))
plot_pca(norm_test)$plot
## how about if we mix and match methods?
norm_test <- sm(normalize_expt(expt, transform="log2", convert="cpm", norm="quant", batch="combat_scale", filter=TRUE, batch_step=4, low_to_zero=TRUE))
plot_pca(norm_test)$plot
## The different batch effect testing methods have a pretty widely ranging effect on the clustering
## play with them by changing the batch= parameter to:
## "limma", "sva", "svaseq", "limmaresid", "ruvg", "combat", combatmod"
pca_test <- plot_pca(norm_test)
head(pca_test$res)
## Thus we see a dramatic decrease in variance accounted for
## by batch after applying limma's 'removebatcheffect'
## (see batch.R2 here vs. above)

## Some metrics are not very useful on (especially quantile) normalized data
norm_graphs <- sm(graph_metrics(norm_test))
norm_graphs$smc
norm_graphs$disheat  ## svaseq's batch correction seems to draw out the signal quite nicely.
## It is worth noting that the wt, early log, thy, replicate c samples are still a bit weird.
norm_graphs$pcaplot
```

# Performing DE analyses

This is a relatively small data set, so performing some differential expression analyses really
should not take long at all.

```{r de_test}
spyogenes_de <- sm(all_pairwise(expt))
spyogenes_tables <- sm(combine_de_tables(spyogenes_de))
spyogenes_sig <- sm(extract_significant_genes(spyogenes_tables))
knitr::kable(head(spyogenes_sig$limma$ups[[1]]))
```

# Make pretty circos graphs

Since most of my circos graphs are for pyogenes, it is likely that the defaults are appropriate for
this particular organism.

Much(all) of the following is taken from the material in tests/testthat/test_70mga.R

```{r circos}
microbe_ids <- as.character(get_microbesonline_ids("pyogenes MGAS5005"))
mgas_df <- sm(get_microbesonline_annotation(microbe_ids[[1]])[[1]])
mgas_df$sysName <- gsub(pattern="Spy_", replacement="Spy", x=mgas_df$sysName)
rownames(mgas_df) <- make.names(mgas_df$sysName, unique=TRUE)


## First make a template configuration
circos_test <- circos_prefix()
## Fill it in with the data for s.pyogenes
circos_kary <- circos_karyotype("mgas", length=1895017)
## Fill in the gene category annotations by gene-strand
circos_plus <- sm(circos_plus_minus(mgas_df, circos_test))

circos_limma_hist <- sm(circos_hist(spyogenes_de$limma$all_tables[[1]], mgas_df, circos_test, outer=circos_plus))
circos_deseq_hist <- sm(circos_hist(spyogenes_de$deseq$all_tables[[1]], mgas_df, circos_test, outer=circos_limma_hist))
circos_edger_hist <- sm(circos_hist(spyogenes_de$edger$all_tables[[1]], mgas_df, circos_test, outer=circos_deseq_hist))
circos_suffix(cfgout=circos_test)
## circos_made <- sm(circos_make(target="mgas"))
## For some reason this fails weirdly when not run interactively.
```

![circos result](circos/mgas.svg)

[index.html](index.html)

```{r sysinfo, results='asis'}
library('pander')
pander(sessionInfo())
```
