---
title: "An Introduction to hpgltools Usage"
author: "atb abelew@gmail.com"
date: "`r Sys.Date()`"
output:
 html_document:
  theme: cosmo
  highlight: tango
  fig_height: 7
  fig_width: 7
  fig_caption: true
  code_folding: show
  self_contained: true
  keep_md: true
  toc: true
  toc_float:
    collapsed: false
    smooth_scroll: false
vignette: >
  %\VignetteIndexEntry{hpgltools_introduction}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---

```{r options, include=FALSE}

library("hpgltools")
knitr::opts_knit$set(
    progress = TRUE,
    verbose = TRUE,
    width = 90,
##    stop_on_error = FALSE,
    echo = TRUE)
knitr::opts_chunk$set(
    ## results = "hold",  ## This is weird
    error = TRUE,
    fig.width = 8,
    fig.height = 8,
    dpi = 96)
options(digits = 4,
        stringsAsFactors = FALSE,
        knitr.duplicate.label = "allow")
ggplot2::theme_set(ggplot2::theme_bw(base_size=10))
set.seed(1)

```

```{r rendering, include=FALSE, eval=FALSE}

hpgltools:::saveme()
hpgltools:::loadme()
rm(list=ls())
## 3 different output formats for rendering reports:
render_filename="hpgltools_byob.Rmd"
rmarkdown::render(render_filename, output_format="pdf_document", output_options=c("skip_html"))
rmarkdown::render(render_filename, output_format="html_document")

render_filename="hpgltools_byob.Rmd"
setwd("~/scratch/hpgltools/vignettes")
rmarkdown::render(render_filename)

```

Hpgltools: helper functions for RNAseq data analysis
====================================================

This document is intended to demonstrate the ways the hpgltools package
may help ease high-throughput data analyses.  To that end a few examples
will be performed using it using data from my work including:

* RNA sequencing analysis
* Ribosome profiling analysis
* Transposon insertion library analyses

When performing these tasks, I use this package for:

* Data distribution visualization and analysis
* Batch effect quantification
* Differential expression analyses with DESeq2/EdgeR/limma and comparisons among them
* Gene Ontology representation via goseq, clusterProfiler, topGO, GOStats, and gProfiler
* KEGG visualization
* (Bacterial) visualization with circos
* Limited motif/ARE searching
* Data export to excel

# Getting ready

Installation of hpgltools is fairly simple

```{r installation, eval=FALSE}

## The easiest way to install hpgltools is via devtools
install.packages("devtools")
devtools::install_github("abelew/hpgltools")
library(hpgltools)

```

It uses many R packages, which are annoying to install piecemeal,
therefore it has the function autoload_all() to help.

```{r startup, eval=FALSE}

library(hpgltools)
## If uncommented, the following line queries the libraries used by hpgltools
## and if they are not available, installs them.

hpgltools::autoloads_all()

## shortcuts for using bioconductor's biocLite() and install_github()
hpgltools::require.auto("elsayedlab/TxDb.LmajorFriedlin.tritryp27.genes") ## Uses install_github()
hpgltools::require.auto("dplyr", update=TRUE) ## uses biocLite() and looks for packages to update.

```

Now that hpgltools has been loaded, let us load an experimental design,
count tables, and annotation data.

# Loading data

In each of the examples above the following pieces of information are required:

* Annontation data as a df or gff (optional but useful)
* Experimental design as csv, excel, or df
* Count tables as a set of files 1/sample or df

## Human macrophage data loading

```{r human_macrophage_loading, cache=TRUE}

library(hpgltools)
setwd("~/scratch/rnaseq_lpanamensis")
lp_gff <- "reference/lpanamensis.gff"
hs_gff <- "reference/hsapiens.gff"
lp_annotations <- gff2df(lp_gff, type="gene")
hs_annotations <- get_biomart_annotations()
head(hs_annotations)
lp_goids <- read.csv(file="reference/lpan_go.txt.xz", sep="\t", header=FALSE)
colnames(lp_goids) <- c("ID","GO","ont","name","source","tag")

hs_inf_lp <- suppressMessages(create_expt(file="all_samples-hsapiens.xlsx"))
lp_alone <- suppressMessages(create_expt(file="all_samples-lpanamensis.xlsx"))
summary(hs_inf_lp)
knitr::kable(head(hs_inf_lp$design))
dim(Biobase::exprs(hs_inf_lp$expressionset))

library(org.Hs.eg.db)
hs_go_ensembl <-load_go_terms(org.Hs.eg.db, hs_annotations$ID)
hs_goids <- hs_go_ensembl[, c("ENSEMBL","GO")]
colnames(hs_goids) <- c("ID","GO")

```

This infection experiment contains 51,041 genes in 50 samples.

A couple of notes about create_expt:

1.  It requires either a csv or xlsx metadata input file _or_ a data frame of metadata.
2.  If that metadata contains a 'file' column, it will attempt to read the files therein, if not
    it will search the 'processed/count_tables' directory for something making sense organised either
    by sample name.  It assumes count tables are gzipped.
3.  It will assign a set of colors with RColorBrewer, but accepts chosen colors
4.  It is happiest with a df of metadata describing the genes, but that is not necessary
5.  Upon completion, it keeps the experimental metadata in expt$design
6.  It keeps a bioconductor Expressionset in expt$expressionset
7.  It maintains the normalization etc. state of the data in expt$state
8.  It keeps a backup of the expressionset in expt$original_expressionset

## Subsetting a large experimental design into smaller pieces

The human infection experiment loaded above is entirely too complex.
Lets extract from it a portion of samples with interesting data
While at it, lets also change the colors.

```{r hs_inf_lp_subset, cache=TRUE}

hs_inf_lp_sub <- hpgltools::expt_subset(hs_inf_lp, subset="condition=='macro_nil'|condition=='macro_sh'|condition=='macro_ch'")
hs_inf_lp_sub$colors <- gsub(pattern="1B9E77", replacement="005500", x=hs_inf_lp_sub$colors)
hs_inf_lp_sub$colors <- gsub(pattern="817C37", replacement="880000", x=hs_inf_lp_sub$colors)
hs_inf_lp_sub$colors <- gsub(pattern="D1600F", replacement="0000FF", x=hs_inf_lp_sub$colors)
dim(Biobase::exprs(hs_inf_lp_sub$expressionset))

```

## Switching gears to yeast

Let us load a data set of yeast data.  This data is rather simpler, no batch effect and fewer samples.
In addition, the count tables are in the processed/ tree rather than the df.

```{r load_sc, cache=TRUE}

setwd("~/scratch/rnaseq_cbf5")
sc = create_expt(file="cbf5_samples.csv", file_suffix="_forward-trimmed-v0M1.count.gz", by_sample=TRUE)
sc_genelengths = hpgltools::get_genelengths("reference/scerevisiae.gff.gz")
sc_goids = read.delim("reference/go_trimmed.csv.gz", sep=",")
colnames(sc_goids) = c("ID","GO","Yeast_ID")
knitr::kable(sc$design)

```

file_suffix and file_prefix allow some flexibility in searching for filenames.

## How about bacteria?

Thus in the bacterial data set, we use both.

```{r load_spy, cache=TRUE}

setwd("~/scratch/rnaseq_mga")
sp <- suppressMessages(create_expt(file="all_samples.csv", sep="\t", file_prefix="07v2M1gen_", file_suffix="_genome.count.gz"))
knitr::kable(sp$design)

```

This data set is a bit problematic, as we will see.

# Visualize the data sets

We now have 3 different data sets loaded into memory.
An immediate question:  how similar are the libraries to one another in them?
The function graph_metrics() graphs the following:

* Library sizes
* The number of non-zero genes vs. CPM by library
* Boxplot showing the data distributions
* Density plot showing the data distributions
* Pairwise correlation/distance heatmaps of the data
* Standard median pairwise correlation/distance
* PCA plot and table of the data
* optional MA and QQ plots of samples vs. median

Some of these metrics do not often make sense for non-normalized data (PCA).

## Running graph_metrics

At this point, none of the previous data sets have been normalized, but we can
still poke at them and see if the data makes general sense.  Thus, even though
PCA plots do not really work for non-log2 non-normalized data, we can see the
effect of the different library sizes on the human experiment (the new samples
cluster to the far right of the pca plot).  In contrast, the qq plot of the
yeast samples shows that they follow very similar distributions compared to one
another and compared the mean of all samples.  Finally, a boxplot of the
S.pyogenes reinforces the fact that the samples at stationary have a different
distribution than all the others.

```{r visualizations, fig.show="hide"}

hs_metrics <- graph_metrics(hs_inf_lp_sub)
sc_metrics <- suppressMessages(graph_metrics(sc, qq=TRUE, ma=TRUE))
sp_metrics <- suppressMessages(graph_metrics(sp))
summary(sc_metrics)

```

The following includes a few of the resulting images for the human data.  I want
to highlight how the plots suggest a likely batch effect, perhaps mediated by
the smaller library sizes for some newer samples.

### Human metrics

Many of the functions in hpgltools are excessively verbose.  This is no exception.
The result is a set of tables, lists, recorded R plots, and ggplot2 objects.
They may be printed one at a time or as a group.

```{r vis_result}

print(hs_metrics$libsize)
## The samples numbered >600 have smaller libraries.

print(hs_metrics$corheat)
## Oddly though, they correlate in clusters which suggest something else is going on.

print(hs_metrics$pcaplot)
## But the new batch (squares) clearly segregates separately.

```

### Yeast metrics

Looking at the yeast data, it is pretty immediately obvious that it is much
more well behaved than the human data.

```{r vis_yeast}

print(sc_metrics$libsize)
## 3 libraries are significantly smaller than the other 4.

print(sc_metrics$nonzero)
## This is highlighted in the non-zero genes plot

print(sc_metrics$density)
## However, the densities are pretty similar

print(sc_metrics$boxplot)
## As are boxplots of non-normalized data (on the auto-detected log scale)

print(sc_metrics$disheat)
## Well, normalization will at least be able to help _something_

```

### Streptococcus initial visualization

In contrast, something strange is going on with the pyogenes data.

```{r sp_vis}

print(sp_metrics$libsize)
## 4 libraries are rather larger than the others

print(sp_metrics$density)
## The densities are a bit concerning

```

# Normalizing and re-graphing

There are more than a few different things one may do to normalize the data including:

1. Remove low-count genes
  * genefilter's pv, cv, pofa functions
  * threshold based filtering from cbcb
2. Normalize counts to dull the effect of outliers
  * DESeq sizefactoring, variance stabilization
  * quantile normalization with normalize.quantiles or cbcb's qsmooth
  * edgeR's TMM normalization, upperquartile, or RLE
3. Convert the resulting data to CPM/RPKM/etc
  * edgeR's cpm/rpkm
  * cp_SEQ_m using instances of arbitrary patterns
4. Minimize batch effects
  * cbcb's batch removal
  * limma's removeBatchEffect()
  * sva's combat/sva/ssva/fsva
  * RUV's RUVg
5. Transform the data to a log scale for easier visualization
  * Can try log2/log10/ln

## Normalization methods

If no arguments are passed to normalize_expt(), then it will leave the data
alone. For each of the 5 sections above, there is an option, as illustrated
in the next block.

```{r perform_normalizations}

hs_norm <- normalize_expt(hs_inf_lp_sub, filter_low=TRUE, norm="quant", convert="cpm", transform="log2", batch="combat")
sc_norm <- suppressMessages(normalize_expt(sc, norm="tmm", convert="cpm"))
sp_norm <- suppressMessages(normalize_expt(sp, norm="rle", convert="cpm", transform="log2"))
summary(hs_norm)
## The same fields are here as from before, but with a few new like 'normalized'

summary(hs_norm$normalized)
## which is a list including the things done, intermediate count tables, and library sizes

hs_norm$normalized$actions
## Here we see that we did log2(combat(cpm(quantile(low-filter(counts)))))

summary(hs_norm$normalized$intermediate_counts)
## Each of these slots contains the eset of each step.

```

The return of normalize_expt is another expt object with a few fields filled in.
This includes 'normalized' which is a list including 'actions' which is a list
of all the modifications performed on the data.  'intermediate_counts' is a
list of the changed count table after each step of the normalization process.
The order of operations is preserved in the order in which they are printed,
thus: input->lowfilter->normalization->conversion->batch->transform.

## Poke at normalized data

Now that these data sets have been normalized, a larger set of plots make sense.
For example, if we did a log2 transformation, then the assumptions of a pca plot
are no longer so thoroughly violated, and the plot should make a lot more sense.

### Human normalized plots

In the following block I will call separate plotting functions, it is worth
noting that they are generally smart enough to tell the difference between
an expt object, an expressionset, or just a df count table (perhaps with a
design and/or colors).

```{r norm_poking}

hs_density <- plot_density(hs_norm)
print(hs_density)
## The quantile normalization really homogenizes the data distributions

hs_cor <- plot_corheat(hs_norm)
## It appears the uninfected looks a lot like self-healing

hs_pca <- plot_pca(hs_norm)
hs_pca$plot
## The pca plot now separates pretty clearly from self-healing/uninfected vs. chronic

hs_pca$res

```

### Yeast normalized plots

In contrast, since the normalized expt is just another expt, we may call
graph_metrics() on it.  I am going to suppress the message from it, too.

```{r sc_norm_graph_metrics, fig.show="hide"}

sc_plots <- suppressMessages(graph_metrics(sc_norm))

```

```{r show_sc_norm}

print(sc_plots$pcaplot)
## hpgl0566 is a bit weird

print(sc_plots$disheat)
## but the clustering is pretty good

print(sc_plots$smd)
## and even that weird sample is well below the standard median distance cutoff

print(sc_plots$density)

```

### Streptococcus pyogenes normalized plots

Even normalization is insufficient to salvage this data, as we can see below.

```{r sp_norm_graph_metrics, fig.show="hide"}

sp_plots <- suppressMessages(graph_metrics(sp_norm, qq=TRUE, ma=TRUE))

```

```{r show_sp_norm}

print(sp_plots$pcaplot)
## Some weird clustering is going on, we can see that there is another
## experimental factor which is much more important than our delineation
## between early/late/stationary.

print(sp_plots$corheat)
## hmm ok

print(sp_plots$ma$HPGL0149_HPGL0150)
## The ma between these samples is a bit weird

print(sp_plots$qqlog)
## clearly some samples are not on the same distribution
## and this is after normalization

```

# Perform a differential expression analysis

Assuming we are satisfied with the data (In the case of the S.pyogenes data, we
explicitly are _not_, and the experiment had to be redone.), we can perform
various differential expression analyses. Some people prefer limma or edger or
deseq, I do not.  But if you do, it is possible to perform these analyses
separately

## Single DE tools

The following blocks will illustrate how to run limma, edgeR, and DESeq2
separately.  In each case, the wrapper will attempt to extract all possible
pairwise comparisons of conditions in the data, and run them.

For these, I will use the yeast data set, which if you will recall, has
only 1 batch.  This is interesting because my tools default to including
batch in their models.  Thus, if you watch the output, you will see its
moment of puzzlement.

### limma

Limma is what we use primarily in our lab, and so I have more options for it
than the other tools.

```{r single_de_limma}

sc_limma <- limma_pairwise(sc_norm)
sc_scatter <- limma_coefficient_scatter(sc_limma)
sc_scatter$scatter
sc_scatter$both_histogram

```

### EdgeR

In contrast, edgeR does not like inputs which have been messed with.  It
requires a happy negative binomial distribution to work, which assuredly
is no longer true when we log2 normalize, for instance.  Therefore,
you can see its moment of puzzlement and decision to use the raw data.

Oh yeah, I used to color all of my dots by distance from the linear
model.  This has not changed for this plot.

```{r single_de_edger}

sc_edger <- edger_pairwise(sc_norm)
sc_scatter <- edger_coefficient_scatter(sc_edger)
sc_scatter$scatter

```

### DESeq2

```{r single_de_deseq}

sc_deseq <- deseq_pairwise(sc_norm)
sc_scatter <- deseq_coefficient_scatter(sc_deseq)
## oops, I broke deseq_coefficient_scatter() FIXME!!

```

### All 3 and a basic non-statistical implementation

I wrote a wrapper for the above 3 tools which does the following:

1. Check if it should include condition or condition+batch in the model
2. Extract all possible conditions
  * A subset of conditions may be provided
  * Generate a list of all possible pairwise comparisons of the conditions
3. Using limma, perform all comparisons
4. Using DESeq2, perform all comparisons
5. Using EdgeR, perform all comparisons
6. Using the basic method, perform all comparisons
7. Perform correlations among the resulting log fold changes

#### Human all-pairwise

When we run all_pairwise on the human data, we will note a few things:
The human data requires quite a bit of modification to make it usable. It is
currently only possible to put batch modified data into EdgeR/DESeq2 if one
adds an extra flag to force the data as input.  (This is because they require
unmodified integer counts).  As a result, we can see that limma does not agree
with _anything_ for this data.

```{r some_de, cache=TRUE}

hs_de <- all_pairwise(hs_norm)
## The data structure presented by doing all these tools is of a necessity
## quite complex.
print(hs_de$comparison$heat)
## This provides a summary of how well the various tools (dis)agree.

## Extracts of the data may be taken:
hs_keepers <- list(
    "chr_vs_sh" = c("macro_ch","macro_sh"))
## This makes a label 'chr_vs_sh', standing for chronic/self-healing
## It uses the macro_ch condition as numerator, and macro_sh as denominator.
hs_combined <- combine_de_tables(hs_de, keepers=hs_keepers, excel=NULL)
hs_combined$plots
## The coefficient scatter plot from limma

hs_sig <- extract_significant_genes(hs_combined, excel=NULL)
## I made some attempt to standardize the columns from the various tools
## when presenting them all together.
knitr::kable(head(hs_sig$limma$ups$chr_vs_sh))

```

The all_pairwise() function does more than we usually want.  When it performs
all possible contrasts, that provides a larger landscape to test that the
various tools (dis)agree, but it also produces tables which are excessive
and may be reversed with respect to our logical way of thinking about the
samples.  Eg. This tool might provide b/a when in fact we care about a/b.
Furthermore, it provides no judgement regarding which genes are
'significant'.

#### Yeast all pairwise

The yeast data has only 1 batch, we can make that explicit when we call all_pairwise()
In addition, the yeast data is relatively well behaved, thus it agrees across the board.

```{r some_de_sc, cache=TRUE}

sc_de <- suppressMessages(all_pairwise(sc_norm, model_batch=FALSE))

sc_combined <- combine_de_tables(sc_de)
sc_combined$plots
## There is a bigger range of data for the yeast, primarily because we didn't have
## to smash it with a comBat

sc_sig <- extract_significant_genes(sc_combined, according_to="edger", fc=0.7, z=1, excel=NULL)

```

As you can see, it is possible to ask for interesting subsets of the available
search space, taking a set of contrasts which might be hundreds long and
extracting the handful in which one has interest.  Furthermore, the definition
of 'significant' may be changed to suit the requirements of the experiment.
Thus the defaults are a +/- 2 fold change with (adj)p <= 0.05.  But one may
instead request genes outside of a z-score cutoff, a top-n, a p-value, adj-p,
or combination.

#### S. pyogenes all pairwise

```{r some_de_sp, cache=TRUE}

sp_de <- suppressMessages(all_pairwise(sp))
sp_keepers <- list(
    "late-early" = c("LL","EL"),
    "stat-early" = c("ST","EL"))
sp_combined <- combine_de_tables(sp_de, keepers=sp_keepers, excel=NULL)
sp_sig <- extract_significant_genes(sp_combined, according_to="all", excel=NULL)
knitr::kable(sp_sig$limma$counts)
knitr::kable(sp_sig$edger$counts)
knitr::kable(sp_sig$deseq$counts)

```

We know a priori that the S.pyogenes data is screwed up, but we can still pass
it along to these tools.  We see that the various tools agree pretty well, but
we probably cannot trust any of these results.

# Gene Ontology Searching

We have beaten the differential expression horse pretty much to death.  Now
let us look at some potential ontology searches.

I take the same approach to ontology searches as I do toward differential
expression analyses.  There are currently 4 main tools used for these
searches in the lab:

* goseq: Relatively consistent and easy, corrects for length biases
* clusterProfiler: More conservative, good visualization tools, human centric
* topGO: Very flexible, nice tree visualization
* GOStats: Tied nicely to bioconductor's other packages, well cited.
* (honorable mention)gProfileR: Nice R->web interface, only works with metazoans

## Single ontology searches

In the same way all_pairwise() wraps the various differential expression tools,
so too do subset_ontology_search() and all_ontology_searches().
But, we may also run the various tools alone.

### goseq

The function simple_goseq() seeks to make a goseq search less onerous.
However, it explicitly requires a table of differentially expressed genes.

```{r simple_goseq}

sc_up <- sc_sig$edger$ups$wt_vs_mut
## sc_genelengths came from waaaaay at the top of this document
sc_goseq <- simple_goseq(sc_up, lengths=sc_genelengths, goids=sc_goids)

knitr::kable(head(sc_goseq$bp_subset))

print(sc_goseq$pvalue_plots$bpp_plot_over)

```

### clusterProfiler

ClusterProfiler is rather more conservative than the other tools.
Also, it takes a long time for it to generate the rdata files it needs to run,
since I already generated them in my yeast working directory, I will just take
advantage of the previously existing files.

```{r simple_clusterprofiler}

setwd("~/scratch/rnaseq_cbf5")
sc_clust <- simple_clusterprofiler(sc_up, goids=sc_goids)

summary(sc_clust)
print(sc_clust$group_plots$mf_group_barplot)

knitr::kable(head(sc_clust$bp_interesting))

```

### topGO

topGO talks too much.  suppressMessages doesn't seem to shut it up, either.
As a result, I am going to set a flag on this block to tell it to ignore
the voluminous output from topgo.

```{r simple_topgo, results="hide"}

setwd("~/scratch/rnaseq_cbf5")
sc_top <- simple_topgo(sc_up)

```

```{r topgo_results}

sc_top$pvalue_plots$bpp_plot_over

knitr::kable(head(sc_top$tables$bp_interesting))

```

### GOstats

GOstats is neat because it is good about using the suite of existing
bioconductor tools.

```{r simple_gostats}

setwd("~/scratch/rnaseq_cbf5")
sc_gost <- simple_gostats(sc_up, gff="reference/scerevisiae.gff.gz", goids=sc_goids, gff_type="gene")
sc_gost$pvalue_plots$bpp_plot_over

```

### gProfiler

gprofiler hasnot yet been incorporated into the all_ontology tools.

```{r gprofiler}

sc_gprof <- simple_gprofiler(sc_up, organism="scerevisiae")
knitr::kable(head(sc_gprof$kegg))
knitr::kable(head(sc_gprof$reactome))

```

### Do all searches in one shot

```{r ontology_searches, cache=TRUE, eval=FALSE}

setwd("~/scratch/rnaseq_lpanamensis")
## This takes forever, I will likely only run single searches for the other organisms
hs_ontologies <- subset_ontology_search(hs_sig$limma, species="hsapiens", gff=hs_gff, goids=hs_goids, gff_type="gene")
hs_ontologies[["up_goseq"]][[1]][["pvalue_plots"]][["bpp_plot_over"]]

hs_ontologies[["up_cluster"]][[1]][["pvalue_plots"]][["bpp_plot_over"]]

hs_ontologies[["up_gostats"]][[1]][["pvalue_plots"]][["bpp_plot_over"]]

hs_ontologies[["up_topgo"]][[1]][["pvalue_plots"]][["bpp_plot_over"]]


```

# Some things not covered

Here are a few topics not included here, but that one may play with in hpgltools:

* ARE/motif searches
* kmeans clustering
* spirographs!
* fancy click-able html/javascript graphs (gvis)
* kegg searches/pathview coloring
* surrogate variable estimations/pca exploration
* experimental model modifications
* circos
* biomart
