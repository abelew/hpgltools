---
title: "hpgltools examples using the fission dataset"
author: "atb abelew@gmail.com"
date: "`r Sys.Date()`"
output: rmarkdown::pdf_document
vignette: >
  %\VignetteIndexEntry{fission examples}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---

# Example hpgltool usage with a real data set (fission)

This document aims to provide further examples in how to use the hpgltools.

Note to self, the header has rmarkdown::pdf_document instead of html_document or html_vignette
because it gets some bullcrap error 'margins too large'...

## Setting up

Here are the commands I invoke to get ready to play with new data, including everything
required to install hpgltools, the software it uses, and the fission data.

```{r setup, include=TRUE}

## These first 4 lines are not needed once hpgltools is installed.
## source("http://bioconductor.org/biocLite.R")
## biocLite("devtools")
## library(devtools)
## install_github("elsayed-lab/hpgltools")
library(hpgltools)
require.auto("fission")
library(fission)
data(fission)
knitr::opts_knit$set(progress=TRUE, verbose=TRUE, error=TRUE,  fig.width=7, fig.height=7)

```

## Data import

All the work I do in Dr. El-Sayed's lab makes some pretty hard
assumptions about how data is stored.  As a result, to use the fission
data set I will do a little bit of shenanigans to match it to the
expected format.  Now that I have played a little with fission, I
think its format is quite nice and am likely to have my experiment
class instead be a SummarizedExperiment.

```{r data_import}

## Extract the meta data from the fission dataset
meta <- as.data.frame(fission@colData)
## Make conditions and batches
meta$condition <- paste(meta$strain, meta$minute, sep=".")
meta$batch <- meta$replicate
meta$sample.id <- rownames(meta)
## Grab the count data
fission_data <- fission@assays$data$counts
## This will make an experiment superclass called 'expt' and it contains
## an ExpressionSet along with any arbitrary additional information one might want to include.
## Along the way it writes a Rdata file which is by default called 'expt.Rdata'
fission_expt <- create_expt(meta_dataframe=meta, count_dataframe=fission_data)

```

## Normalizing and exploring data

There are lots of toys we have learned to use to play with with raw
data and explore stuff like batch effects or non-canonical
distributions or skewed counts.  hpgltools provides some functionality
to make this process easier.  The graphs shown below and many more are
generated with the wrapper 'graph_metrics()' but that takes away the
chance to explain the graphs as I generate them.

```{r norm_explore}

## First make a bar plot of the library sizes in the experiment.
## Notice that the colors were auto-chosen by create_expt() and they should
## be maintained throughout this process
fis_libsize <- hpgl_libsize(fission_expt)
fis_libsize
## Here we see that the wild type replicate 3 sample for 15 minutes has fewer non-zero genes than all its friends.
fis_nonzero <- hpgl_nonzero(fission_expt, labels="boring", title="nonzero vs. cpm")
fis_nonzero

```

### An initial pca plot

In most cases, raw data does not cluster very well, lets see if that
is also true for the fission experiment. Assuming it doesn't, lets
normalize the data using the defaults (cpm, quantile, log2) and try
again.

```{r pca}

## Something in this is causing a build loop on travis...

## I am no longer certain that code is maintained, what remains from it I might pull in to my own.
## require.auto("kokrah/cbcbSEQ")  ## Install Kwame's cbcbSEQ
## Unsurprisingly, the raw data doesn't cluster well at all...
fis_rawpca <- hpgl_pca(fission_expt, expt_labels=fission_expt$condition)
fis_rawpca$plot
## So, normalize the data
norm_expt <- normalize_expt(fission_expt, transform="log2", norm="quant", convert="cpm")
## And try the pca again
fis_normpca <- hpgl_pca(norm_expt, plot_labels="boring", title="normalized pca")
fis_normpca$plot

normbatch_expt <- normalize_expt(fission_expt, transform="log2", norm="quant", convert="cpm", batch="sva")
fis_normbatchpca <- hpgl_pca(normbatch_expt, title="Normalized PCA with batch effect correction.")
fis_normbatchpca$plot
## ok, that caused the 0, 60, 15, and 30 minute samples to cluster nicely
## the 120 and 180 minute samples are still a bit tight

## pca_information provides some more information about the call to
## fast.svd that went into making the pca plot
fis_info <- pca_information(norm_expt, expt_factors=c("condition","batch","strain","minute"), num_components=6)
## The r^2 table shows that quite a lot of the variance in the data is explained by condition
head(fis_info$rsquared_table)
## We can look at the correlation between the principle components and the factors in the experiment
## in this case looking at condition/batch vs the first 4 components.
fis_info$pca_cor
## And p-values to lend some credence(or not to those assertions)
fis_info$anova_p

## Try again with batch removed data
batchnorm_expt <- normalize_expt(fission_expt, batch="limma", norm="quant", transform="log2", convert="cpm")
fis_batchnormpca <- hpgl_pca(batchnorm_expt, plot_title="limma corrected pca")
fis_batchnormpca$plot
test_pca <- pca_information(batchnorm_expt, expt_factors=c("condition","batch","strain","minute"), num_components=6)

```

Interesting, the batch normalized pca plot looks much the same as the
normalized. The variances are in fact pretty much the exact same...

## Look at the data distributions

We have some tools which provide visualizations of the distribution of
the data:

```{r distributions}

hpgl_boxplot(fission_expt)
sf_expt <- normalize_expt(fission_expt, norm="sf")
hpgl_boxplot(sf_expt)
tm_expt <- normalize_expt(fission_expt, norm="tmm")
hpgl_boxplot(tm_expt)
rle_expt <- normalize_expt(fission_expt, norm="rle")
hpgl_boxplot(rle_expt)
up_expt <- normalize_expt(fission_expt, norm="upperquartile")
hpgl_boxplot(up_expt)

hpgl_density(norm_expt)
hpgl_density(sf_expt)
hpgl_density(tm_expt)

compare_12 <- hpgl_qq_plot(fission_expt, x=1, y=2)
compare_12$log

```

## See how they cluster

Ok, so we can further check out how the data cluster with respect to
one another...

```{r clustering}

hpgl_corheat(norm_expt)
hpgl_corheat(batchnorm_expt)
hpgl_disheat(norm_expt)
hpgl_disheat(batchnorm_expt)

```

# Some simple differential expression analyses

Travis wisely imposes a limit on the amount of time for building vignettes.
My tools by default will attempt all possible pairwise comparisons, which takes a long time.
Therefore I am going to take a subset of the data and limit these comparisons to that.

```{r simple_subset}

fun_data <- expt_subset(fission_expt, subset="condition=='wt.120'|condition=='mut.120'")
fun_norm <- normalize_expt(fun_data, batch="limma", norm="quant", transform="log2", convert="cpm")

```

## Try using limma first

```{r simple_limma}

limma_comparison <- limma_pairwise(fun_norm)
names(limma_comparison$all_tables)
summary(limma_comparison$all_tables$wt.120_vs_mut.120)
wt_120 <- limma_comparison$all_tables$wt.120
mut_120 <- limma_comparison$all_tables$mut.120
scatter_wt_mut <- limma_coefficient_scatter(limma_comparison, x="wt.120", y="mut.120", gvis_filename=NULL)
scatter_wt_mut$scatter
scatter_wt_mut$both_histogram

```

## Then DESeq2

```{r simple_deseq2}

deseq_comparison <- deseq2_pairwise(fun_data, model_batch=TRUE)
summary(deseq_comparison$all_tables$wt.120_vs_mut.120)

```

## And EdgeR

```{r simple_edger}

edger_comparison <- edger_pairwise(fun_data, model_batch=TRUE)
summary(edger_comparison$all_tables$wt.120_vs_mut.120)

```

## My stupid basic comparison

```{r simple_basic}

basic_comparison <- basic_pairwise(fun_data)
summary(basic_comparison$all_tables$wt.120_vs_mut.120)

```

## Combine them all

```{r simple_all}

all_comparisons <- all_pairwise(fun_data, model_batch=TRUE)
all_combined <- combine_de_tables(all_comparisons)
sig_genes <- extract_significant_genes(all_combined, sig_table=NULL)

```

## Ontology searches

```{r ontology, eval=FALSE}

limma_results <- limma_comparison$all_tables
## The set of comparisons performed
names(limma_results)
table <- limma_results$wt.180_vs_wt.0
dim(table)
gene_names <- rownames(table)

updown_genes <- get_sig_genes(table)
##orthologs <- read.table("ftp://ftp.ebi.ac.uk/pub/databases/pombase/pombe/orthologs/cerevisiae-orthologs.txt")
##colnames(orthologs) <- c("pombe","cerevisiae")

##head(updown_genes$up_genes)
##updown_genes$up_genes = merge(updown_genes$up_genes, orthologs, by.x="row.names", by.y="pombe")
##rownames(updown_genes$up_genes) = make.names(updown_genes$up_genes$cerevisiae, unique=TRUE)
##updown_genes$down_genes = merge(updown_genes$down_genes, orthologs, by.x="row.names", by.y="pombe")
##rownames(updown_genes$down_genes) = make.names(updown_genes$down_genes$cerevisiae, unique=TRUE)

require.auto("GenomicFeatures")
require.auto("biomaRt")
ensembl_pombe = biomaRt::useMart("fungal_mart", dataset="spombe_eg_gene", host="fungi.ensembl.org")
pombe_filters = biomaRt::listFilters(ensembl_pombe)
head(pombe_filters, n=20) ## 11 looks to be my guy

## getBM(attributes=c('hgnc_symbol', 'chromosome_name', 'start_position', 'end_position'), filters='with_ontology_go', values="", mart=ensemble_pombe)
pombe_goids = getBM(attributes=c('pombase_gene_name', 'go_accession'), values=gene_names, mart=ensembl_pombe)
colnames(pombe_goids) = c("ID","GO")
pombe = makeTxDbFromBiomart(biomart ="fungal_mart", dataset = "spombe_eg_gene", host="fungi.ensembl.org")
pombe_transcripts = as.data.frame(transcriptsBy(pombe))
lengths = pombe_transcripts[,c("group_name","width")]
colnames(lengths) = c("ID","width")
## Something useful I didn't notice before:
## makeTranscriptDbFromGFF()  ## From GenomicFeatures, much like my own gff2df()

goseq_search = simple_goseq(de_genes=updown_genes$up_genes, lengths=lengths, goids=pombe_goids)
##spombe_gff = download.file(url="http://www.broadinstitute.org/ftp/pub/annotation/fungi/schizosaccharomyces/genomes/schizosaccharomyces_pombe/schizosaccharomyces_pombe_972h-_2_transcripts.gtf", destfile="pombe.gff")
##cluster_search = simple_clusterprofiler(de_genes=updown_genes$up_genes, goids=pombe_goids, gff="pombe.gff")
##topgo_search = simple_topgo(de_genes=updown_genes$up_genes, goids_df=pombe_goids)
##gostats_search = simple_gostats(de_genes=updown_genes$up_genes, gff="pombe.gff", goids=pombe_goids, universe_merge="gene_id")

```
