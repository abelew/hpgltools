---
title: "hpgltools usage"
author: "atb abelew@gmail.com"
date: "`r Sys.Date()`"
output: rmarkdown::pdf_document
vignette: >
  %\VignetteIndexEntry{hpgltools_usage}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---

Using hpgltools for fun and profit!
===================================

hpgltools was written to make working with high-throughput data
analyses easier. These analyses generally fall into a few stages:

1.  Data visualization and outlier/batch evaluation
2.  Differential expression analyses
 a. Visualization and export of these results
3.  Gene ontology/KEGG analyses
 a. Visualization and export of these results

Before any of these tasks may be performed, the data must be loaded
into memory.  hpgltools attempts to make this easier with
create_expt() and subset_expt().

# Loading (meta)data and annotations

The following examples will use a real data set from a recent
experiment in our lab.  The raw data was processed using a mix of
trimmomatic, biopieces, bowtie, samtools, and htseq.  The final count
tables were deposited into the 'preprocessing/count_tables/' tree.
The resulting data structure was named 'most_v0M1,' named because it
is comprised of count tables with 0 mismatches and 1 randomly-placed
multi-match.

The annotation file was mgas_5005.gff.xz residing in
'reference/gff/'.

The count tables and meta-data were loaded through the create_expt()
function and the genome annotations were loaded with gff2df().

```{r loading_data}
library(hpgltools)
data_file <- system.file("hpgltools.rda", package="hpgltools")
load(data_file, envir=globalenv())

ls()
## The gff information is in 'annotations'
## The experiment is in most_v0M1
## Here is the meta-data! (well, the first 6 lines anyway).
knitr::kable(head(most_v0M1$definitions))

## We can re-create the experiment using it:
meta <- most_v0M1$definitions
## This is a terrible thing to do, never do it outside of a demonstration!
meta$batch <- gsub(pattern="b", replacement="a", x=meta$batch)
counts <- Biobase::exprs(most_v0M1$expressionset)
## Originally the meta-data was kept in a file: all_samples.csv
expt <- create_expt(meta_dataframe=meta, count_dataframe=counts)
summary(expt)
```

The data structure generated by create_expt() is a list containing the
following slots:

* initial_metadata:        A backup of the metadata
* original_expressionset:  A backup of the raw counts
* expressionset:           The current count data
* samples:                 A data frame of metadata used for subsets
* design:                  The design of the experiment
* definitions:             Extended design information, these are
  probably redundant and should be pruned.
* stages:                  The experimental stage
* types:                   Cell types
* conditions:              Experimental condition
* batches:                 Experimental batch
* samplenames:             Names of the samples
* colors:                  Colors chosen for graphs and such
* names:                   Bringing together the condition/batch
* filtered:                low-count filtering status of the counts
* transform:               transformation applied to the counts
* norm:                    normalization applied to the counts
* convert:                 cpm/rpkm/etc applied to the data
* original_libsize:        the library sizes before normalization
* columns:                 A backup of the sample names

One possibility would be to examine the data in its unmolested state:

```{r graph_original}
raw_metrics <- s_p(graph_metrics(expt, qq=TRUE))$result
## View a raw library size plot
raw_metrics$libsize
## Or boxplot to see the data distribution
raw_metrics$boxplot
## The warning is because it automatically uses a log scale and there are some 0 count genes.
## Perhaps you prefer density plots
raw_metrics$density
## quantile/quantile plots compared to the median of all samples
raw_metrics$qqrat
## Here we can see some samples are differently 'shaped' compared to the median than others
## There are other plots one may view, but this data set is a bit too crowded as is.
## The following summary shows the other available plots:
summary(raw_metrics)
```

On the other hand, we might take a subset of the data to
focus on the late-log vs. early-log samples.

The expt_subset() function allows one to pull material from the
experimental design.

Once we have a smaller data set, we can more easily use PCA to see how
the sample separate.

```{r subset_data}
head(expt$definition)
## elt stands for: "early/late in thy"
elt <- expt_subset(expt, subset="(stage=='EL'|stage=='LL')&type=='WT'&grepl(pattern='_thy', x=condition)")

elt_metrics <- graph_metrics(elt)
elt_metrics$pcaplot
head(elt_metrics$pcares)
```

It is pretty obvious that the raw data is a bit jumbled according to
PCA.  This is not paricularly suprising since we didn't normalize it
at all.

```{r normalize_subset}
## doing nothing to the data except log2 transforming it has a surprisingly large effect
norm_test <- normalize_expt(elt, transform="log2")
plot_pca(norm_test)$plot
## a quantile normalization alone affect some, but not all of the data
norm_test <- normalize_expt(elt, norm="quant")
plot_pca(norm_test)$plot
## cpm alone brings out some samples, too
norm_test <- normalize_expt(elt, convert="cpm")
plot_pca(norm_test)$plot
## low count filtering has some effect, too
norm_test <- normalize_expt(elt, filter_low="pofa")
plot_pca(norm_test)$plot
## how about if we mix and match methods?
norm_test <- normalize_expt(elt, transform="log2", convert="cpm", norm="quant", batch="combat_scale", filter_low=TRUE, batch_step=4)
plot_pca(norm_test)$plot
## The different batch effect testing methods have a pretty widely ranging effect on the clustering
## play with them by changing the batch= parameter to:
## "limma", "sva", "svaseq", "limmaresid", "ruvg", "combat", combatmod"
pca_test <- plot_pca(norm_test)
head(pca_test$res)
## Thus we see a dramatic decrease in variance accounted for
## by batch after applying limma's 'removebatcheffect'
## (see batch.R2 here vs. above)

## Some metrics are not very useful on (especially quantile) normalized data
norm_graphs <- graph_metrics(norm_test)
norm_graphs$smc
norm_graphs$disheat  ## svaseq's batch correction seems to draw out the signal quite nicely.
## It is worth noting that the wt, early log, thy, replicate c samples are still a bit weird.
```
